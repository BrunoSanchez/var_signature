{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta M - Delta t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the deltamdeltat diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mira = pd.read_csv('ATLAS_LC/MIRA_features_table.csv')\n",
    "signature_cols = [col for col in df_mira.columns if 'Deltam' in col]\n",
    "#plt.imshow(df_mira[signature_cols].iloc[2787].as_matrix().reshape(23, 24).T, cmap='inferno')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_cols += ['OBJID', 'filter', 'CLASS']\n",
    "df_mira = df_mira[signature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mpulse = pd.read_csv('ATLAS_LC/MPULSE_features_table.csv')[signature_cols]\n",
    "df_dbf = pd.read_csv('ATLAS_LC/DBF_features_table.csv')[signature_cols]\n",
    "df_lpv = pd.read_csv('ATLAS_LC/LPV_features_table.csv')[signature_cols]\n",
    "df_dbh = pd.read_csv('ATLAS_LC/DBH_features_table.csv')[signature_cols]\n",
    "df_pulse = pd.read_csv('ATLAS_LC/PULSE_features_table.csv')[signature_cols]\n",
    "df_nsine = pd.read_csv('ATLAS_LC/NSINE_features_table.csv')[signature_cols]\n",
    "df_sine = pd.read_csv('ATLAS_LC/SINE_features_table.csv')[signature_cols]\n",
    "df_msine = pd.read_csv('ATLAS_LC/MSINE_features_table.csv')[signature_cols]\n",
    "df_cbh = pd.read_csv('ATLAS_LC/CBH_features_table.csv')[signature_cols]\n",
    "df_cbf = pd.read_csv('ATLAS_LC/CBF_features_table.csv')[signature_cols]\n",
    "df_irr = pd.read_csv('ATLAS_LC/IRR_features_table.csv')[signature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/bsanchez/.virtualenvs/benv/lib/python2.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.concat([df_mira, df_mpulse, df_dbf, df_lpv, df_dbh, df_pulse, \n",
    "                       df_nsine, df_sine, df_msine, df_cbf, df_cbh])\n",
    "signature_cols = [col for col in df_mira.columns if 'Deltam' in col]\n",
    "X = full_data[signature_cols].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_mira)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_mpulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_dbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_lpv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_dbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_pulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_cbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_cbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_nsine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_sine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_msine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.10, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326278, 552)\n",
      "(36254, 552)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the size of our encoded representations\n",
    "encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(23*24,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activity_regularizer=regularizers.l1(10e-5), activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(23*24, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: 4.3377 - val_loss: 0.7396\n",
      "Epoch 2/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: 0.6564 - val_loss: 0.5937\n",
      "Epoch 3/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: 0.5560 - val_loss: 0.5190\n",
      "Epoch 4/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: 0.4875 - val_loss: 0.4547\n",
      "Epoch 5/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: 0.4239 - val_loss: 0.3917\n",
      "Epoch 6/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: 0.3607 - val_loss: 0.3284\n",
      "Epoch 7/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: 0.2972 - val_loss: 0.2649\n",
      "Epoch 8/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: 0.2334 - val_loss: 0.2010\n",
      "Epoch 9/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: 0.1692 - val_loss: 0.1368\n",
      "Epoch 10/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: 0.1048 - val_loss: 0.0724\n",
      "Epoch 11/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: 0.0402 - val_loss: 0.0077\n",
      "Epoch 12/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.0247 - val_loss: -0.0573\n",
      "Epoch 13/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.0899 - val_loss: -0.1226\n",
      "Epoch 14/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: -0.1554 - val_loss: -0.1881\n",
      "Epoch 15/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.2212 - val_loss: -0.2540\n",
      "Epoch 16/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: -0.2873 - val_loss: -0.3202\n",
      "Epoch 17/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.3538 - val_loss: -0.3868\n",
      "Epoch 18/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.4207 - val_loss: -0.4537\n",
      "Epoch 19/50\n",
      "326278/326278 [==============================] - 8s 25us/step - loss: -0.4879 - val_loss: -0.5211\n",
      "Epoch 20/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.5556 - val_loss: -0.5889\n",
      "Epoch 21/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.6238 - val_loss: -0.6572\n",
      "Epoch 22/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.6924 - val_loss: -0.7260\n",
      "Epoch 23/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.7615 - val_loss: -0.7953\n",
      "Epoch 24/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.8312 - val_loss: -0.8651\n",
      "Epoch 25/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.9014 - val_loss: -0.9355\n",
      "Epoch 26/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -0.9722 - val_loss: -1.0064\n",
      "Epoch 27/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -1.0435 - val_loss: -1.0779\n",
      "Epoch 28/50\n",
      "326278/326278 [==============================] - 8s 23us/step - loss: -1.1154 - val_loss: -1.1500\n",
      "Epoch 29/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -1.1879 - val_loss: -1.2227\n",
      "Epoch 30/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -1.2609 - val_loss: -1.2960\n",
      "Epoch 31/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -1.3346 - val_loss: -1.3699\n",
      "Epoch 32/50\n",
      "326278/326278 [==============================] - 8s 23us/step - loss: -1.4089 - val_loss: -1.4444\n",
      "Epoch 33/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -1.4839 - val_loss: -1.5194\n",
      "Epoch 34/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -1.5594 - val_loss: -1.5952\n",
      "Epoch 35/50\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -1.6355 - val_loss: -1.6715\n",
      "Epoch 36/50\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -1.7122 - val_loss: -1.7484\n",
      "Epoch 37/50\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -1.7896 - val_loss: -1.8260\n",
      "Epoch 38/50\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -1.8676 - val_loss: -1.9041\n",
      "Epoch 39/50\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: -1.9462 - val_loss: -1.9829\n",
      "Epoch 40/50\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -2.0253 - val_loss: -2.0622\n",
      "Epoch 41/50\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: -2.1051 - val_loss: -2.1422\n",
      "Epoch 42/50\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: -2.1855 - val_loss: -2.2228\n",
      "Epoch 43/50\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -2.2665 - val_loss: -2.3040\n",
      "Epoch 44/50\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: -2.3482 - val_loss: -2.3857\n",
      "Epoch 45/50\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -2.4303 - val_loss: -2.4680\n",
      "Epoch 46/50\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -2.5131 - val_loss: -2.5510\n",
      "Epoch 47/50\n",
      "326278/326278 [==============================] - 8s 23us/step - loss: -2.5965 - val_loss: -2.6345\n",
      "Epoch 48/50\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -2.6804 - val_loss: -2.7186\n",
      "Epoch 49/50\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -2.7650 - val_loss: -2.8033\n",
      "Epoch 50/50\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -2.8501 - val_loss: -2.8886\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/10\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -2.9169 - val_loss: -2.9366\n",
      "Epoch 2/10\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -2.9650 - val_loss: -2.9847\n",
      "Epoch 3/10\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -3.0135 - val_loss: -3.0330\n",
      "Epoch 4/10\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -3.0620 - val_loss: -3.0818\n",
      "Epoch 5/10\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -3.1108 - val_loss: -3.1303\n",
      "Epoch 6/10\n",
      "326278/326278 [==============================] - 8s 24us/step - loss: -3.1597 - val_loss: -3.1794\n",
      "Epoch 7/10\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -3.2088 - val_loss: -3.2284\n",
      "Epoch 8/10\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -3.2580 - val_loss: -3.2777\n",
      "Epoch 9/10\n",
      "326278/326278 [==============================] - 8s 23us/step - loss: -3.3075 - val_loss: -3.3273\n",
      "Epoch 10/10\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -3.3571 - val_loss: -3.3768\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -3.4706 - val_loss: -3.5532\n",
      "Epoch 2/20\n",
      "326278/326278 [==============================] - 9s 26us/step - loss: -3.6490 - val_loss: -3.7325\n",
      "Epoch 3/20\n",
      "326278/326278 [==============================] - 9s 26us/step - loss: -3.8294 - val_loss: -3.9124\n",
      "Epoch 4/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.0121 - val_loss: -4.1019\n",
      "Epoch 5/20\n",
      "326278/326278 [==============================] - 9s 26us/step - loss: -4.1967 - val_loss: -4.2744\n",
      "Epoch 6/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.3808 - val_loss: -4.4920\n",
      "Epoch 7/20\n",
      "326278/326278 [==============================] - 9s 26us/step - loss: -4.5818 - val_loss: -4.6495\n",
      "Epoch 8/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.6920 - val_loss: -4.7337\n",
      "Epoch 9/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.7644 - val_loss: -4.7834\n",
      "Epoch 10/20\n",
      "326278/326278 [==============================] - 8s 26us/step - loss: -4.8109 - val_loss: -4.8217\n",
      "Epoch 11/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.8491 - val_loss: -4.8620\n",
      "Epoch 12/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.8860 - val_loss: -4.8944\n",
      "Epoch 13/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.9189 - val_loss: -4.9273\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.9528 - val_loss: -4.9619\n",
      "Epoch 15/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -4.9815 - val_loss: -4.9831\n",
      "Epoch 16/20\n",
      "326278/326278 [==============================] - 8s 26us/step - loss: -5.0038 - val_loss: -5.0078\n",
      "Epoch 17/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -5.0253 - val_loss: -5.0261\n",
      "Epoch 18/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -5.0414 - val_loss: -5.0430\n",
      "Epoch 19/20\n",
      "326278/326278 [==============================] - 9s 26us/step - loss: -5.0580 - val_loss: -5.0558\n",
      "Epoch 20/20\n",
      "326278/326278 [==============================] - 9s 27us/step - loss: -5.0719 - val_loss: -5.0709\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/20\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -5.0815 - val_loss: -5.0763\n",
      "Epoch 2/20\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -5.0870 - val_loss: -5.0827\n",
      "Epoch 3/20\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -5.0923 - val_loss: -5.0864\n",
      "Epoch 4/20\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -5.0978 - val_loss: -5.0940\n",
      "Epoch 5/20\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -5.1044 - val_loss: -5.0995\n",
      "Epoch 6/20\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -5.1091 - val_loss: -5.1032\n",
      "Epoch 7/20\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -5.1140 - val_loss: -5.1106\n",
      "Epoch 8/20\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -5.1200 - val_loss: -5.1142\n",
      "Epoch 9/20\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -5.1236 - val_loss: -5.1179\n",
      "Epoch 10/20\n",
      "326278/326278 [==============================] - 7s 23us/step - loss: -5.1273 - val_loss: -5.1218\n",
      "Epoch 11/20\n",
      "326278/326278 [==============================] - 7s 22us/step - loss: -5.1309 - val_loss: -5.1253\n",
      "Epoch 12/20\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -5.1347 - val_loss: -5.1288\n",
      "Epoch 13/20\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -5.1379 - val_loss: -5.1325\n",
      "Epoch 14/20\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: -5.1420 - val_loss: -5.1360\n",
      "Epoch 15/20\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: -5.1450 - val_loss: -5.1388\n",
      "Epoch 16/20\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: -5.1494 - val_loss: -5.1435\n",
      "Epoch 17/20\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: -5.1526 - val_loss: -5.1465\n",
      "Epoch 18/20\n",
      "326278/326278 [==============================] - 7s 21us/step - loss: -5.1557 - val_loss: -5.1494\n",
      "Epoch 19/20\n",
      "326278/326278 [==============================] - 6s 20us/step - loss: -5.1591 - val_loss: -5.1557\n",
      "Epoch 20/20\n",
      "326278/326278 [==============================] - 6s 20us/step - loss: -5.1648 - val_loss: -5.1589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb091e9ec50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=5000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=9000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=20,\n",
    "                batch_size=2500,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=20,\n",
    "                batch_size=5000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some lightcurves\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(X_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 6  # how many digits we will display\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    j = np.random.randint(0, high=len(X_test))\n",
    "    plt.imshow(X_test[j].reshape(23, 24).T, cmap='inferno')\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[j].reshape(23, 24).T, cmap='inferno')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode every data \n",
    "encoded_imgs = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362532, 64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = pd.DataFrame()\n",
    "enc['OBJID'] = full_data['OBJID']\n",
    "enc['filter'] = full_data['filter']\n",
    "enc['CLASS'] = full_data['CLASS']\n",
    "for i in range(encoding_dim):\n",
    "    enc['encode_{}'.format(i+1)] = encoded_imgs[:, i]\n",
    "enc.to_csv('ATLAS_LC/deltamdeltat_{}_encoded.csv'.format(encoded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisicadecoded_imgs = decoder.predict(encoded_imgs)\n",
    "dec = pd.DataFrame()\n",
    "dec['OBJID'] = full_data['OBJID']\n",
    "dec['filter'] = full_data['filter']\n",
    "dec['CLASS'] = full_data['CLASS']\n",
    "for i in range(23*24):\n",
    "    dec['encode_{}'.format(i+1)] = decoded_imgs[:, i]\n",
    "dec.to_csv('ATLAS_LC/deltamdeltat_{}_decoded.csv'.format(decoded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
