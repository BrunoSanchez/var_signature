{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta M - Delta t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the deltamdeltat diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mira = pd.read_csv('ATLAS_LC/MIRA_features_table.csv')\n",
    "signature_cols = [col for col in df_mira.columns if 'Deltam' in col]\n",
    "#plt.imshow(df_mira[signature_cols].iloc[2787].as_matrix().reshape(23, 24).T, cmap='inferno')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signature_cols += ['OBJID', 'filter', 'CLASS']\n",
    "df_mira = df_mira[signature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mpulse = pd.read_csv('ATLAS_LC/MPULSE_features_table.csv')[signature_cols]\n",
    "df_dbf = pd.read_csv('ATLAS_LC/DBF_features_table.csv')[signature_cols]\n",
    "df_lpv = pd.read_csv('ATLAS_LC/LPV_features_table.csv')[signature_cols]\n",
    "df_dbh = pd.read_csv('ATLAS_LC/DBH_features_table.csv')[signature_cols]\n",
    "df_pulse = pd.read_csv('ATLAS_LC/PULSE_features_table.csv')[signature_cols]\n",
    "df_nsine = pd.read_csv('ATLAS_LC/NSINE_features_table.csv')[signature_cols]\n",
    "df_sine = pd.read_csv('ATLAS_LC/SINE_features_table.csv')[signature_cols]\n",
    "df_msine = pd.read_csv('ATLAS_LC/MSINE_features_table.csv')[signature_cols]\n",
    "df_cbh = pd.read_csv('ATLAS_LC/CBH_features_table.csv')[signature_cols]\n",
    "df_cbf = pd.read_csv('ATLAS_LC/CBF_features_table.csv')[signature_cols]\n",
    "df_irr = pd.read_csv('ATLAS_LC/IRR_features_table.csv')[signature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/.virtualenvs/daily/lib/python2.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.concat([df_mira, df_mpulse, df_dbf, df_lpv, df_dbh, df_pulse, \n",
    "                       df_nsine, df_sine, df_msine, df_cbf, df_cbh])\n",
    "signature_cols = [col for col in df_mira.columns if 'Deltam' in col]\n",
    "X = full_data[signature_cols].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_mira)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_mpulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_dbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_lpv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_dbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_pulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_cbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_cbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_nsine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_sine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_msine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.10, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326278, 552)\n",
      "(36254, 552)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this is the size of our encoded representations\n",
    "encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(23*24,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(23*24, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/50\n",
      "326278/326278 [==============================] - 14s 43us/step - loss: -4.6350 - val_loss: -5.6940\n",
      "Epoch 2/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.7541 - val_loss: -5.7912\n",
      "Epoch 3/50\n",
      "326278/326278 [==============================] - 13s 39us/step - loss: -5.8208 - val_loss: -5.8444\n",
      "Epoch 4/50\n",
      "326278/326278 [==============================] - 13s 38us/step - loss: -5.8742 - val_loss: -5.8864\n",
      "Epoch 5/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.8996 - val_loss: -5.9015\n",
      "Epoch 6/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9117 - val_loss: -5.9125\n",
      "Epoch 7/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9219 - val_loss: -5.9219\n",
      "Epoch 8/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9299 - val_loss: -5.9292\n",
      "Epoch 9/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9367 - val_loss: -5.9361\n",
      "Epoch 10/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9423 - val_loss: -5.9403\n",
      "Epoch 11/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9472 - val_loss: -5.9446\n",
      "Epoch 12/50\n",
      "326278/326278 [==============================] - 13s 39us/step - loss: -5.9516 - val_loss: -5.9480\n",
      "Epoch 13/50\n",
      "326278/326278 [==============================] - 13s 39us/step - loss: -5.9554 - val_loss: -5.9530\n",
      "Epoch 14/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9586 - val_loss: -5.9553\n",
      "Epoch 15/50\n",
      "326278/326278 [==============================] - 13s 39us/step - loss: -5.9614 - val_loss: -5.9583\n",
      "Epoch 16/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9642 - val_loss: -5.9606\n",
      "Epoch 17/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9667 - val_loss: -5.9632\n",
      "Epoch 18/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9690 - val_loss: -5.9659\n",
      "Epoch 19/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9712 - val_loss: -5.9675\n",
      "Epoch 20/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9729 - val_loss: -5.9697\n",
      "Epoch 21/50\n",
      "326278/326278 [==============================] - 13s 38us/step - loss: -5.9750 - val_loss: -5.9709\n",
      "Epoch 22/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -5.9768 - val_loss: -5.9745\n",
      "Epoch 23/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9784 - val_loss: -5.9754\n",
      "Epoch 24/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9801 - val_loss: -5.9764\n",
      "Epoch 25/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9818 - val_loss: -5.9792\n",
      "Epoch 26/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9827 - val_loss: -5.9800\n",
      "Epoch 27/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9849 - val_loss: -5.9812\n",
      "Epoch 28/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9858 - val_loss: -5.9824\n",
      "Epoch 29/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -5.9870 - val_loss: -5.9835\n",
      "Epoch 30/50\n",
      "326278/326278 [==============================] - 13s 39us/step - loss: -5.9882 - val_loss: -5.9854\n",
      "Epoch 31/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -5.9895 - val_loss: -5.9858\n",
      "Epoch 32/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -5.9904 - val_loss: -5.9883\n",
      "Epoch 33/50\n",
      "326278/326278 [==============================] - 14s 42us/step - loss: -5.9915 - val_loss: -5.9879\n",
      "Epoch 34/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -5.9929 - val_loss: -5.9899\n",
      "Epoch 35/50\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -5.9942 - val_loss: -5.9910\n",
      "Epoch 36/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -5.9957 - val_loss: -5.9920\n",
      "Epoch 37/50\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -5.9964 - val_loss: -5.9934\n",
      "Epoch 38/50\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -5.9975 - val_loss: -5.9932\n",
      "Epoch 39/50\n",
      "326278/326278 [==============================] - 14s 42us/step - loss: -5.9983 - val_loss: -5.9956\n",
      "Epoch 40/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -5.9997 - val_loss: -5.9961\n",
      "Epoch 41/50\n",
      "326278/326278 [==============================] - 13s 39us/step - loss: -6.0009 - val_loss: -5.9976\n",
      "Epoch 42/50\n",
      "326278/326278 [==============================] - 14s 42us/step - loss: -6.0018 - val_loss: -5.9979\n",
      "Epoch 43/50\n",
      "326278/326278 [==============================] - 14s 42us/step - loss: -6.0027 - val_loss: -5.9995\n",
      "Epoch 44/50\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0038 - val_loss: -6.0002\n",
      "Epoch 45/50\n",
      "326278/326278 [==============================] - 14s 42us/step - loss: -6.0050 - val_loss: -6.0010\n",
      "Epoch 46/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0056 - val_loss: -6.0019\n",
      "Epoch 47/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0064 - val_loss: -6.0025\n",
      "Epoch 48/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0073 - val_loss: -6.0039\n",
      "Epoch 49/50\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0082 - val_loss: -6.0049\n",
      "Epoch 50/50\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0092 - val_loss: -6.0060\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/10\n",
      "326278/326278 [==============================] - 15s 45us/step - loss: -6.0101 - val_loss: -6.0055\n",
      "Epoch 2/10\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0099 - val_loss: -6.0067\n",
      "Epoch 3/10\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0109 - val_loss: -6.0072\n",
      "Epoch 4/10\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0111 - val_loss: -6.0072\n",
      "Epoch 5/10\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0115 - val_loss: -6.0078\n",
      "Epoch 6/10\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0122 - val_loss: -6.0089\n",
      "Epoch 7/10\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0127 - val_loss: -6.0079\n",
      "Epoch 8/10\n",
      "326278/326278 [==============================] - 14s 42us/step - loss: -6.0122 - val_loss: -6.0089\n",
      "Epoch 9/10\n",
      "326278/326278 [==============================] - 14s 42us/step - loss: -6.0133 - val_loss: -6.0102\n",
      "Epoch 10/10\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0144 - val_loss: -6.0106\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/20\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0153 - val_loss: -6.0122\n",
      "Epoch 2/20\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0170 - val_loss: -6.0134\n",
      "Epoch 3/20\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0184 - val_loss: -6.0148\n",
      "Epoch 4/20\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0199 - val_loss: -6.0170\n",
      "Epoch 5/20\n",
      "326278/326278 [==============================] - 13s 40us/step - loss: -6.0211 - val_loss: -6.0180\n",
      "Epoch 6/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0226 - val_loss: -6.0192\n",
      "Epoch 7/20\n",
      "326278/326278 [==============================] - 14s 42us/step - loss: -6.0237 - val_loss: -6.0191\n",
      "Epoch 8/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0251 - val_loss: -6.0221\n",
      "Epoch 9/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0261 - val_loss: -6.0225\n",
      "Epoch 10/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0271 - val_loss: -6.0238\n",
      "Epoch 11/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0283 - val_loss: -6.0251\n",
      "Epoch 12/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0291 - val_loss: -6.0262\n",
      "Epoch 13/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0304 - val_loss: -6.0263\n",
      "Epoch 14/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0309 - val_loss: -6.0281\n",
      "Epoch 15/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0324 - val_loss: -6.0292\n",
      "Epoch 16/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0331 - val_loss: -6.0299\n",
      "Epoch 17/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0339 - val_loss: -6.0307\n",
      "Epoch 18/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0351 - val_loss: -6.0316\n",
      "Epoch 19/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0359 - val_loss: -6.0324\n",
      "Epoch 20/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0366 - val_loss: -6.0332\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/20\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0365 - val_loss: -6.0332\n",
      "Epoch 2/20\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0376 - val_loss: -6.0341\n",
      "Epoch 3/20\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0378 - val_loss: -6.0339\n",
      "Epoch 4/20\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0383 - val_loss: -6.0351\n",
      "Epoch 5/20\n",
      "326278/326278 [==============================] - 13s 38us/step - loss: -6.0391 - val_loss: -6.0352\n",
      "Epoch 6/20\n",
      "326278/326278 [==============================] - 13s 38us/step - loss: -6.0391 - val_loss: -6.0359\n",
      "Epoch 7/20\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0394 - val_loss: -6.0354\n",
      "Epoch 8/20\n",
      "326278/326278 [==============================] - 13s 38us/step - loss: -6.0398 - val_loss: -6.0358\n",
      "Epoch 9/20\n",
      "326278/326278 [==============================] - 13s 39us/step - loss: -6.0405 - val_loss: -6.0372\n",
      "Epoch 10/20\n",
      "326278/326278 [==============================] - 13s 38us/step - loss: -6.0412 - val_loss: -6.0377\n",
      "Epoch 11/20\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0411 - val_loss: -6.0378\n",
      "Epoch 12/20\n",
      "326278/326278 [==============================] - 13s 38us/step - loss: -6.0414 - val_loss: -6.0373\n",
      "Epoch 13/20\n",
      "326278/326278 [==============================] - 13s 38us/step - loss: -6.0417 - val_loss: -6.0384\n",
      "Epoch 14/20\n",
      "326278/326278 [==============================] - 13s 41us/step - loss: -6.0422 - val_loss: -6.0385\n",
      "Epoch 15/20\n",
      "326278/326278 [==============================] - 12s 38us/step - loss: -6.0427 - val_loss: -6.0393\n",
      "Epoch 16/20\n",
      "326278/326278 [==============================] - 12s 37us/step - loss: -6.0431 - val_loss: -6.0396\n",
      "Epoch 17/20\n",
      "326278/326278 [==============================] - 12s 37us/step - loss: -6.0436 - val_loss: -6.0397\n",
      "Epoch 18/20\n",
      "326278/326278 [==============================] - 12s 37us/step - loss: -6.0434 - val_loss: -6.0399\n",
      "Epoch 19/20\n",
      "326278/326278 [==============================] - 12s 37us/step - loss: -6.0441 - val_loss: -6.0407\n",
      "Epoch 20/20\n",
      "326278/326278 [==============================] - 12s 37us/step - loss: -6.0446 - val_loss: -6.0404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b7a69fb90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=5000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=9000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=20,\n",
    "                batch_size=2500,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=20,\n",
    "                batch_size=5000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode and decode some lightcurves\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(X_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1AAAAEYCAYAAABSjxcZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEbqogIdrmvDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 6  # how many digits we will display\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    j = np.random.randint(0, high=len(X_test))\n",
    "    plt.imshow(X_test[j].reshape(23, 24).T, cmap='inferno')\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[j].reshape(23, 24).T, cmap='inferno')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode every data \n",
    "encoded_imgs = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362532, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = pd.DataFrame()\n",
    "enc['OBJID'] = full_data['OBJID']\n",
    "enc['filter'] = full_data['filter']\n",
    "enc['CLASS'] = full_data['CLASS']\n",
    "for i in range(encoding_dim):\n",
    "    enc['encode_{}'.format(i+1)] = encoded_imgs[:, i]\n",
    "enc.to_csv('ATLAS_LC/deltamdeltat_{}_encoded.csv'.format(encoded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-eb553e43a6fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encode_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ATLAS_LC/deltamdeltat_{}_decoded.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/bruno/.virtualenvs/daily/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bruno/.virtualenvs/daily/local/lib/python2.7/site-packages/pandas/io/formats/csvs.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;31m# GH 17778 handles zip compression for byte strings separately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 f, handles = _get_handle(path_or_buf, self.mode,\n",
      "\u001b[0;32m/usr/lib/python2.7/StringIO.pyc\u001b[0m in \u001b[0;36mgetvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0m_complain_ifclosed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuflist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuflist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuflist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "dec = pd.DataFrame()\n",
    "dec['OBJID'] = full_data['OBJID']\n",
    "dec['filter'] = full_data['filter']\n",
    "dec['CLASS'] = full_data['CLASS']\n",
    "for i in range(23*24):\n",
    "    dec['encode_{}'.format(i+1)] = decoded_imgs[:, i]\n",
    "dec.to_csv('ATLAS_LC/deltamdeltat_{}_decoded.csv'.format(decoded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
