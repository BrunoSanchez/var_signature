{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/.virtualenvs/daily/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Con curvas de luz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mira = pd.read_csv('ATLAS_LC/MIRA_features_table.csv')\n",
    "signature_cols = [col for col in df_mira.columns if 'Signature' in col]\n",
    "signature_cols += ['OBJID', 'filter', 'CLASS']\n",
    "df_mira = df_mira[signature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mpulse = pd.read_csv('ATLAS_LC/MPULSE_features_table.csv')[signature_cols]\n",
    "df_dbf = pd.read_csv('ATLAS_LC/DBF_features_table.csv')[signature_cols]\n",
    "df_lpv = pd.read_csv('ATLAS_LC/LPV_features_table.csv')[signature_cols]\n",
    "df_dbh = pd.read_csv('ATLAS_LC/DBH_features_table.csv')[signature_cols]\n",
    "df_pulse = pd.read_csv('ATLAS_LC/PULSE_features_table.csv')[signature_cols]\n",
    "df_nsine = pd.read_csv('ATLAS_LC/NSINE_features_table.csv')[signature_cols]\n",
    "df_sine = pd.read_csv('ATLAS_LC/SINE_features_table.csv')[signature_cols]\n",
    "df_msine = pd.read_csv('ATLAS_LC/MSINE_features_table.csv')[signature_cols]\n",
    "df_cbh = pd.read_csv('ATLAS_LC/CBH_features_table.csv')[signature_cols]\n",
    "df_cbf = pd.read_csv('ATLAS_LC/CBF_features_table.csv')[signature_cols]\n",
    "df_irr = pd.read_csv('ATLAS_LC/IRR_features_table.csv')[signature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/.virtualenvs/daily/lib/python2.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.concat([df_mira, df_mpulse, df_dbf, df_lpv, df_dbh, df_pulse, \n",
    "                       df_nsine, df_sine, df_msine, df_cbf, df_cbh])\n",
    "signature_cols = [col for col in df_mira.columns if 'Signature' in col]\n",
    "X = full_data[signature_cols].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_mira)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_mpulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_dbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_lpv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_dbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_pulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_cbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_cbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_nsine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_sine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_msine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(df_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.10, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326278, 216)\n",
      "(36254, 216)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the size of our encoded representations\n",
    "encoding_dim = 64  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(216,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activity_regularizer=regularizers.l1(10e-5), activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(216, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/50\n",
      "326278/326278 [==============================] - 6s 19us/step - loss: 3.4663 - val_loss: 1.1824\n",
      "Epoch 2/50\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.9492 - val_loss: 0.7995\n",
      "Epoch 3/50\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.7316 - val_loss: 0.6844\n",
      "Epoch 4/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.6615 - val_loss: 0.6437\n",
      "Epoch 5/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.6330 - val_loss: 0.6231\n",
      "Epoch 6/50\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.6159 - val_loss: 0.6085\n",
      "Epoch 7/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.6025 - val_loss: 0.5962\n",
      "Epoch 8/50\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.5909 - val_loss: 0.5854\n",
      "Epoch 9/50\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.5805 - val_loss: 0.5756\n",
      "Epoch 10/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.5711 - val_loss: 0.5667\n",
      "Epoch 11/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.5627 - val_loss: 0.5586\n",
      "Epoch 12/50\n",
      "326278/326278 [==============================] - 6s 18us/step - loss: 0.5549 - val_loss: 0.5513\n",
      "Epoch 13/50\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.5479 - val_loss: 0.5445\n",
      "Epoch 14/50\n",
      "326278/326278 [==============================] - 7s 20us/step - loss: 0.5414 - val_loss: 0.5384\n",
      "Epoch 15/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.5355 - val_loss: 0.5327\n",
      "Epoch 16/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.5301 - val_loss: 0.5275\n",
      "Epoch 17/50\n",
      "326278/326278 [==============================] - 6s 19us/step - loss: 0.5251 - val_loss: 0.5227\n",
      "Epoch 18/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.5205 - val_loss: 0.5182\n",
      "Epoch 19/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.5162 - val_loss: 0.5141\n",
      "Epoch 20/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.5122 - val_loss: 0.5102\n",
      "Epoch 21/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.5085 - val_loss: 0.5065\n",
      "Epoch 22/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.5049 - val_loss: 0.5031\n",
      "Epoch 23/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.5016 - val_loss: 0.4999\n",
      "Epoch 24/50\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.4985 - val_loss: 0.4968\n",
      "Epoch 25/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4955 - val_loss: 0.4939\n",
      "Epoch 26/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4927 - val_loss: 0.4911\n",
      "Epoch 27/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4899 - val_loss: 0.4884\n",
      "Epoch 28/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4873 - val_loss: 0.4858\n",
      "Epoch 29/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4848 - val_loss: 0.4833\n",
      "Epoch 30/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4823 - val_loss: 0.4809\n",
      "Epoch 31/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4800 - val_loss: 0.4785\n",
      "Epoch 32/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4777 - val_loss: 0.4762\n",
      "Epoch 33/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4754 - val_loss: 0.4740\n",
      "Epoch 34/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4732 - val_loss: 0.4718\n",
      "Epoch 35/50\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.4711 - val_loss: 0.4696\n",
      "Epoch 36/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4690 - val_loss: 0.4675\n",
      "Epoch 37/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4669 - val_loss: 0.4655\n",
      "Epoch 38/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4649 - val_loss: 0.4634\n",
      "Epoch 39/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4629 - val_loss: 0.4614\n",
      "Epoch 40/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4609 - val_loss: 0.4594\n",
      "Epoch 41/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4589 - val_loss: 0.4574\n",
      "Epoch 42/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4570 - val_loss: 0.4554\n",
      "Epoch 43/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4550 - val_loss: 0.4535\n",
      "Epoch 44/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4531 - val_loss: 0.4516\n",
      "Epoch 45/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4512 - val_loss: 0.4497\n",
      "Epoch 46/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4493 - val_loss: 0.4477\n",
      "Epoch 47/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4475 - val_loss: 0.4458\n",
      "Epoch 48/50\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4456 - val_loss: 0.4440\n",
      "Epoch 49/50\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.4437 - val_loss: 0.4421\n",
      "Epoch 50/50\n",
      "326278/326278 [==============================] - 6s 18us/step - loss: 0.4419 - val_loss: 0.4402\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/10\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4404 - val_loss: 0.4397\n",
      "Epoch 2/10\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.4394 - val_loss: 0.4386\n",
      "Epoch 3/10\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4383 - val_loss: 0.4376\n",
      "Epoch 4/10\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4373 - val_loss: 0.4365\n",
      "Epoch 5/10\n",
      "326278/326278 [==============================] - 6s 18us/step - loss: 0.4363 - val_loss: 0.4355\n",
      "Epoch 6/10\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.4352 - val_loss: 0.4344\n",
      "Epoch 7/10\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4342 - val_loss: 0.4334\n",
      "Epoch 8/10\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4332 - val_loss: 0.4323\n",
      "Epoch 9/10\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4321 - val_loss: 0.4313\n",
      "Epoch 10/10\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.4311 - val_loss: 0.4303\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/20\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.4288 - val_loss: 0.4257\n",
      "Epoch 2/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4251 - val_loss: 0.4221\n",
      "Epoch 3/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.4215 - val_loss: 0.4184\n",
      "Epoch 4/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.4179 - val_loss: 0.4147\n",
      "Epoch 5/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.4143 - val_loss: 0.4111\n",
      "Epoch 6/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.4106 - val_loss: 0.4074\n",
      "Epoch 7/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.4070 - val_loss: 0.4037\n",
      "Epoch 8/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.4034 - val_loss: 0.4002\n",
      "Epoch 9/20\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.3998 - val_loss: 0.3966\n",
      "Epoch 10/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.3961 - val_loss: 0.3928\n",
      "Epoch 11/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3925 - val_loss: 0.3895\n",
      "Epoch 12/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3887 - val_loss: 0.3849\n",
      "Epoch 13/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3851 - val_loss: 0.3802\n",
      "Epoch 14/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3813 - val_loss: 0.3789\n",
      "Epoch 15/20\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.3800 - val_loss: 0.3776\n",
      "Epoch 16/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3787 - val_loss: 0.3763\n",
      "Epoch 17/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3774 - val_loss: 0.3750\n",
      "Epoch 18/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.3762 - val_loss: 0.3737\n",
      "Epoch 19/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.3749 - val_loss: 0.3724\n",
      "Epoch 20/20\n",
      "326278/326278 [==============================] - 5s 15us/step - loss: 0.3736 - val_loss: 0.3712\n",
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/20\n",
      "326278/326278 [==============================] - 6s 18us/step - loss: 0.3727 - val_loss: 0.3709\n",
      "Epoch 2/20\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.3721 - val_loss: 0.3702\n",
      "Epoch 3/20\n",
      "326278/326278 [==============================] - 5s 17us/step - loss: 0.3714 - val_loss: 0.3695\n",
      "Epoch 4/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3708 - val_loss: 0.3690\n",
      "Epoch 5/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3701 - val_loss: 0.3683\n",
      "Epoch 6/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3695 - val_loss: 0.3676\n",
      "Epoch 7/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3689 - val_loss: 0.3670\n",
      "Epoch 8/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3683 - val_loss: 0.3664\n",
      "Epoch 9/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3676 - val_loss: 0.3658\n",
      "Epoch 10/20\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.3670 - val_loss: 0.3651\n",
      "Epoch 11/20\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.3664 - val_loss: 0.3643\n",
      "Epoch 12/20\n",
      "326278/326278 [==============================] - 6s 18us/step - loss: 0.3657 - val_loss: 0.3638\n",
      "Epoch 13/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3651 - val_loss: 0.3632\n",
      "Epoch 14/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3644 - val_loss: 0.3625\n",
      "Epoch 15/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3638 - val_loss: 0.3618\n",
      "Epoch 16/20\n",
      "326278/326278 [==============================] - 5s 16us/step - loss: 0.3632 - val_loss: 0.3611\n",
      "Epoch 17/20\n",
      "326278/326278 [==============================] - 6s 18us/step - loss: 0.3626 - val_loss: 0.3607\n",
      "Epoch 18/20\n",
      "326278/326278 [==============================] - 6s 19us/step - loss: 0.3619 - val_loss: 0.3599\n",
      "Epoch 19/20\n",
      "326278/326278 [==============================] - 6s 19us/step - loss: 0.3614 - val_loss: 0.3596\n",
      "Epoch 20/20\n",
      "326278/326278 [==============================] - 6s 17us/step - loss: 0.3605 - val_loss: 0.3586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86b3fb20d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=5000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=9000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=20,\n",
    "                batch_size=2500,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=20,\n",
    "                batch_size=5000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "# encode and decode some lightcurves\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(X_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMEAAADuCAYAAAAwYRD9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAIHtKMAAAAACy93+yO8LTZg0f4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1728x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 4  # how many digits we will display\n",
    "plt.figure(figsize=(24, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    j = np.random.randint(0, high=len(X_test))\n",
    "    plt.imshow(X_test[j].reshape(18, 12).T, cmap='inferno')\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[j].reshape(18, 12).T, cmap='inferno')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode every data \n",
    "encoded_imgs = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362532, 64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = pd.DataFrame()\n",
    "enc['OBJID'] = full_data['OBJID']\n",
    "enc['filter'] = full_data['filter']\n",
    "enc['CLASS'] = full_data['CLASS']\n",
    "for i in range(encoding_dim):\n",
    "    enc['encode_{}'.format(i+1)] = encoded_imgs[:, i]\n",
    "enc.to_csv('ATLAS_LC/signatures_{}_encoded.csv'.format(encoded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "dec = pd.DataFrame()\n",
    "dec['OBJID'] = full_data['OBJID']\n",
    "dec['filter'] = full_data['filter']\n",
    "dec['CLASS'] = full_data['CLASS']\n",
    "for i in range(216):\n",
    "    dec['encode_{}'.format(i+1)] = decoded_imgs[:, i]\n",
    "dec.to_csv('ATLAS_LC/signatures_{}_decoded.csv'.format(decoded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
