{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/.virtualenvs/daily/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 18, 12, 16)\n",
      "(?, 9, 6, 16)\n",
      "(?, 9, 6, 8)\n",
      "(?, 3, 3, 8)\n",
      "This is the bottleneck\n",
      "(?, 3, 3, 8)\n",
      "(?, 9, 6, 8)\n",
      "(?, 9, 6, 16)\n",
      "(?, 18, 12, 16)\n",
      "(?, 18, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(18, 12, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (2, 2), activation='relu', padding='same')(input_img)\n",
    "print x.shape\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "print x.shape\n",
    "x = Conv2D(8, (2, 2), activation='relu', padding='same')(x)\n",
    "print x.shape\n",
    "#x = MaxPooling2D((3, 2), padding='same')(x)\n",
    "#print x.shape\n",
    "#x = Conv2D(8, (3, 2), activation='relu', padding='same')(x)\n",
    "#print x.shape\n",
    "encoded = MaxPooling2D((3, 2), padding='same')(x)\n",
    "print encoded.shape\n",
    "\n",
    "# at this point the representation is ### altered(3, 3, 8) i.e. 128-dimensional\n",
    "print 'This is the bottleneck'\n",
    "\n",
    "x = Conv2D(8, (2, 2), activation='relu', padding='same')(encoded)\n",
    "print x.shape\n",
    "x = UpSampling2D((3, 2))(x)\n",
    "print x.shape\n",
    "#x = Conv2D(8, (2, 2), activation='relu', padding='same')(x)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (2, 2), activation='relu', padding='same')(x)\n",
    "print x.shape\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "print x.shape\n",
    "decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
    "print decoded.shape\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(3, 3, 8))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layers = autoencoder.layers[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_model = decoder_layers[0](encoded_input)\n",
    "composed_model = decoder_layers[1](composed_model)\n",
    "composed_model = decoder_layers[2](composed_model)\n",
    "composed_model = decoder_layers[3](composed_model)\n",
    "composed_model = decoder_layers[4](composed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the decoder model\n",
    "decoder = Model(encoded_input, composed_model)\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mira = pd.read_csv('ATLAS_LC/MIRA_features_table.csv')\n",
    "signature_cols = [col for col in df_mira.columns if 'Signature' in col]\n",
    "signature_cols += ['OBJID', 'filter', 'CLASS']\n",
    "df_mira = df_mira[signature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mpulse = pd.read_csv('ATLAS_LC/MPULSE_features_table.csv')[signature_cols]\n",
    "df_dbf = pd.read_csv('ATLAS_LC/DBF_features_table.csv')[signature_cols]\n",
    "df_lpv = pd.read_csv('ATLAS_LC/LPV_features_table.csv')[signature_cols]\n",
    "df_dbh = pd.read_csv('ATLAS_LC/DBH_features_table.csv')[signature_cols]\n",
    "df_pulse = pd.read_csv('ATLAS_LC/PULSE_features_table.csv')[signature_cols]\n",
    "df_nsine = pd.read_csv('ATLAS_LC/NSINE_features_table.csv')[signature_cols]\n",
    "df_sine = pd.read_csv('ATLAS_LC/SINE_features_table.csv')[signature_cols]\n",
    "df_msine = pd.read_csv('ATLAS_LC/MSINE_features_table.csv')[signature_cols]\n",
    "df_cbh = pd.read_csv('ATLAS_LC/CBH_features_table.csv')[signature_cols]\n",
    "df_cbf = pd.read_csv('ATLAS_LC/CBF_features_table.csv')[signature_cols]\n",
    "df_irr = pd.read_csv('ATLAS_LC/IRR_features_table.csv')[signature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([df_mira, df_mpulse, df_dbf, df_lpv, df_dbh, df_pulse, \n",
    "                       df_nsine, df_sine, df_msine, df_cbf, df_cbh], sort=False)\n",
    "\n",
    "X = full_data[signature_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_mira)\n",
    "del(df_dbf)\n",
    "del(df_lpv)\n",
    "del(df_dbh)\n",
    "del(df_pulse)\n",
    "del(df_nsine)\n",
    "del(df_sine)\n",
    "del(df_msine)\n",
    "del(df_cbh)\n",
    "del(df_cbf)\n",
    "del(df_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X.reshape(X.shape[0], 18, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(data, test_size=0.10, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 12, 1)\n",
      "(36254, 18, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326278 samples, validate on 36254 samples\n",
      "Epoch 1/50\n",
      "326278/326278 [==============================] - 48s 146us/step - loss: 0.4767 - val_loss: 0.1628\n",
      "Epoch 2/50\n",
      "326278/326278 [==============================] - 50s 153us/step - loss: 0.0869 - val_loss: -0.1390\n",
      "Epoch 3/50\n",
      "326278/326278 [==============================] - 51s 155us/step - loss: -0.1616 - val_loss: -0.2972\n",
      "Epoch 4/50\n",
      "326278/326278 [==============================] - 49s 149us/step - loss: -0.3417 - val_loss: -0.4117\n",
      "Epoch 5/50\n",
      "326278/326278 [==============================] - 48s 147us/step - loss: -0.4842 - val_loss: -0.5430\n",
      "Epoch 6/50\n",
      "326278/326278 [==============================] - 52s 160us/step - loss: -0.5734 - val_loss: -0.6359\n",
      "Epoch 7/50\n",
      "326278/326278 [==============================] - 56s 172us/step - loss: -0.6323 - val_loss: -0.6740\n",
      "Epoch 8/50\n",
      "326278/326278 [==============================] - 57s 175us/step - loss: -0.6830 - val_loss: -0.7151\n",
      "Epoch 9/50\n",
      "326278/326278 [==============================] - 56s 172us/step - loss: -0.7168 - val_loss: -0.7456\n",
      "Epoch 10/50\n",
      "326278/326278 [==============================] - 56s 171us/step - loss: -0.7485 - val_loss: -0.7846\n",
      "Epoch 11/50\n",
      "326278/326278 [==============================] - 56s 170us/step - loss: -0.7747 - val_loss: -0.7876\n",
      "Epoch 12/50\n",
      "326278/326278 [==============================] - 60s 183us/step - loss: -0.7967 - val_loss: -0.8210\n",
      "Epoch 13/50\n",
      "326278/326278 [==============================] - 49s 151us/step - loss: -0.8153 - val_loss: -0.8200\n",
      "Epoch 14/50\n",
      "326278/326278 [==============================] - 49s 150us/step - loss: -0.8301 - val_loss: -0.8478\n",
      "Epoch 15/50\n",
      "326278/326278 [==============================] - 46s 141us/step - loss: -0.8447 - val_loss: -0.8627\n",
      "Epoch 16/50\n",
      "326278/326278 [==============================] - 47s 143us/step - loss: -0.8577 - val_loss: -0.8604\n",
      "Epoch 17/50\n",
      "326278/326278 [==============================] - 46s 142us/step - loss: -0.8681 - val_loss: -0.8851\n",
      "Epoch 18/50\n",
      "326278/326278 [==============================] - 47s 143us/step - loss: -0.8808 - val_loss: -0.8891\n",
      "Epoch 19/50\n",
      "326278/326278 [==============================] - 47s 143us/step - loss: -0.8889 - val_loss: -0.9085\n",
      "Epoch 20/50\n",
      "326278/326278 [==============================] - 46s 142us/step - loss: -0.8999 - val_loss: -0.9155\n",
      "Epoch 21/50\n",
      "326278/326278 [==============================] - 46s 142us/step - loss: -0.9081 - val_loss: -0.9247\n",
      "Epoch 22/50\n",
      "326278/326278 [==============================] - 46s 142us/step - loss: -0.9158 - val_loss: -0.9354\n",
      "Epoch 23/50\n",
      "326278/326278 [==============================] - 47s 143us/step - loss: -0.9234 - val_loss: -0.9328\n",
      "Epoch 24/50\n",
      "326278/326278 [==============================] - 47s 144us/step - loss: -0.9291 - val_loss: -0.9338\n",
      "Epoch 25/50\n",
      "326278/326278 [==============================] - 46s 142us/step - loss: -0.9346 - val_loss: -0.9425\n",
      "Epoch 26/50\n",
      "326278/326278 [==============================] - 46s 142us/step - loss: -0.9412 - val_loss: -0.9447\n",
      "Epoch 27/50\n",
      "326278/326278 [==============================] - 46s 141us/step - loss: -0.9464 - val_loss: -0.9715\n",
      "Epoch 28/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9539 - val_loss: -0.9692\n",
      "Epoch 29/50\n",
      "326278/326278 [==============================] - 44s 135us/step - loss: -0.9593 - val_loss: -0.9730\n",
      "Epoch 30/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9626 - val_loss: -0.9758\n",
      "Epoch 31/50\n",
      "326278/326278 [==============================] - 44s 135us/step - loss: -0.9685 - val_loss: -0.9789\n",
      "Epoch 32/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9726 - val_loss: -0.9872\n",
      "Epoch 33/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9780 - val_loss: -0.9718\n",
      "Epoch 34/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9804 - val_loss: -0.9863\n",
      "Epoch 35/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9830 - val_loss: -0.9898\n",
      "Epoch 36/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9897 - val_loss: -0.9874\n",
      "Epoch 37/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9924 - val_loss: -0.9980\n",
      "Epoch 38/50\n",
      "326278/326278 [==============================] - 45s 137us/step - loss: -0.9957 - val_loss: -1.0036\n",
      "Epoch 39/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -0.9986 - val_loss: -1.0040\n",
      "Epoch 40/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -1.0022 - val_loss: -1.0092\n",
      "Epoch 41/50\n",
      "326278/326278 [==============================] - 44s 135us/step - loss: -1.0056 - val_loss: -1.0262\n",
      "Epoch 42/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -1.0108 - val_loss: -1.0138\n",
      "Epoch 43/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -1.0103 - val_loss: -1.0237\n",
      "Epoch 44/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -1.0159 - val_loss: -1.0285\n",
      "Epoch 45/50\n",
      "326278/326278 [==============================] - 45s 139us/step - loss: -1.0175 - val_loss: -1.0238\n",
      "Epoch 46/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -1.0198 - val_loss: -1.0364\n",
      "Epoch 47/50\n",
      "326278/326278 [==============================] - 44s 135us/step - loss: -1.0218 - val_loss: -1.0303\n",
      "Epoch 48/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -1.0241 - val_loss: -1.0444\n",
      "Epoch 49/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -1.0273 - val_loss: -1.0349\n",
      "Epoch 50/50\n",
      "326278/326278 [==============================] - 44s 136us/step - loss: -1.0288 - val_loss: -1.0367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8fc8ff3910>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=6000,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "# encode and decode some lightcurves\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(X_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs_full = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMEAAADuCAYAAAAwYRD9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAACieIRgAAAAAxTMEAwAAAKB4/wczaBZ8cIXVEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1728x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 4  # how many digits we will display\n",
    "plt.figure(figsize=(24, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    j = np.random.randint(0, high=len(X_test))\n",
    "    plt.imshow(X_test[j, :, :, 0].T, cmap='inferno')\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs_full[j, :, :, 0].T, cmap='inferno')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
